{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic gates with Neural Networks (Backpropogation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vuhF9_IXMES6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function: Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EXh6FrflPcam"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Implementing the sigmoid function for x.\n",
    "    sig(x) = 1/(1+e^-x)\n",
    "\n",
    "    Args:\n",
    "        x: input for which signmoid function needs to be calculated.\n",
    "\n",
    "    Returns:\n",
    "        the sigmoid function.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + (np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "csmFAxGqQ4oK"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    \"\"\"Implementing the sigmoid function for x.\n",
    "    sig'(x) = x * (1-x)\n",
    "\n",
    "    Args:\n",
    "        x: input for which derivative of signmoid function needs to be calculated.\n",
    "\n",
    "    Returns:\n",
    "        the derivative of sigmoid function.\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting input, `X` and output, `Y_target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_output():\n",
    "    outputs = {\n",
    "        'and': [[0], [0], [0], [1]], 'nand': [[1], [1], [1], [0]], 'or': [[0], [1], [1], [1]],\n",
    "        'nor': [[1], [0], [0], [0]], 'xor': [[0], [1], [1], [0]], 'xnor': [[1], [0], [0], [1]]\n",
    "    }\n",
    "\n",
    "    lg = \"\"\"\n",
    "    █░░ █▀▀█ █▀▀▀ ░▀░ █▀▀ 　 █▀▀▀ █▀▀█ ▀▀█▀▀ █▀▀ █▀▀ \n",
    "    █░░ █░░█ █░▀█ ▀█▀ █░░ 　 █░▀█ █▄▄█ ░░█░░ █▀▀ ▀▀█ \n",
    "    ▀▀▀ ▀▀▀▀ ▀▀▀▀ ▀▀▀ ▀▀▀ 　 ▀▀▀▀ ▀░░▀ ░░▀░░ ▀▀▀ ▀▀▀\n",
    "    \n",
    "    A B | AND NAND OR NOR XOR XNOR\n",
    "    -------------------------------\n",
    "    0 0 |  0    1   0  1   0   1\n",
    "    0 1 |  0    1   1  0   1   0\n",
    "    1 0 |  0    1   1  0   1   0\n",
    "    1 1 |  1    0   1  0   0   1\n",
    "    \"\"\"\n",
    "    print(lg)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            output_gate = input('Enter your chosen logic gate: ').lower()\n",
    "            break\n",
    "        except KeyError:\n",
    "            print('Invalid logic gate, try again!\\n')\n",
    "\n",
    "    return np.array(outputs[output_gate]), output_gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQwdCVjJVTgv",
    "outputId": "1f7fca58-1426-49bc-e075-369c6b6e2727"
   },
   "outputs": [],
   "source": [
    "def train_network(initial_weights, total_epochs=200000):\n",
    "    print(f\"\\n---------- STARTING TRAINING FOR {total_epochs} ----------\\n\")\n",
    "\n",
    "    W1, W2 = initial_weights\n",
    "\n",
    "    for epoch in range(1, total_epochs+1):\n",
    "        # forward propagation\n",
    "        Z = np.dot(X, W1)\n",
    "        H = sigmoid(Z)\n",
    "\n",
    "        U = np.dot(H, W2)\n",
    "        Y = sigmoid(U)\n",
    "\n",
    "        # calculate Loss function (Mean Square error loss)\n",
    "        E = abs(Y - Y_target)\n",
    "        L = 1/2 * (np.power(E, 2))\n",
    "\n",
    "        # backpropagation - Stage 1\n",
    "        dL_dY = Y - Y_target\n",
    "        dY_dU = Y * (1-Y)\n",
    "        dU_dW2 = H\n",
    "\n",
    "        dL_dW2 = np.dot(dU_dW2.T,dL_dY*dY_dU)\n",
    "\n",
    "        # weight updates in stage 1\n",
    "        W2 -= lr*dL_dW2\n",
    "\n",
    "        # backpropagation - Stage 2\n",
    "        dL_dY = Y-Y_target\n",
    "        dY_dU = Y*(1-Y)\n",
    "        dU_dH = W2\n",
    "        dH_dZ = H*(1-H)\n",
    "        dZ_dW1 = X\n",
    "\n",
    "        dL_dH = np.dot(dL_dY*dY_dU,dU_dH.T)\n",
    "        dL_dW1 = np.dot(dZ_dW1.T,dH_dZ*dL_dH)\n",
    "\n",
    "        # weight updates in stage 2\n",
    "        W1 -= lr*dL_dW1\n",
    "\n",
    "        if epoch % 20000 == 0:\n",
    "            print(\"%6d -   %5s: %.4f    %8s: %.4f\" % (epoch, 'Error', E.sum(), 'MSE loss', L.sum()))\n",
    "\n",
    "    print(\"\\n---------- ENDING TRAINING ----------\")\n",
    "\n",
    "    return W1, W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    █░░ █▀▀█ █▀▀▀ ░▀░ █▀▀ 　 █▀▀▀ █▀▀█ ▀▀█▀▀ █▀▀ █▀▀ \n",
      "    █░░ █░░█ █░▀█ ▀█▀ █░░ 　 █░▀█ █▄▄█ ░░█░░ █▀▀ ▀▀█ \n",
      "    ▀▀▀ ▀▀▀▀ ▀▀▀▀ ▀▀▀ ▀▀▀ 　 ▀▀▀▀ ▀░░▀ ░░▀░░ ▀▀▀ ▀▀▀\n",
      "    \n",
      "    A B | AND NAND OR NOR XOR XNOR\n",
      "    -------------------------------\n",
      "    0 0 |  0    1   0  1   0   1\n",
      "    0 1 |  0    1   1  0   1   0\n",
      "    1 0 |  0    1   1  0   1   0\n",
      "    1 1 |  1    0   1  0   0   1\n",
      "    \n",
      "Enter your chosen logic gate: xor\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate: 0.05\n",
      "\n",
      "---------- STARTING TRAINING FOR 100000 ----------\n",
      "\n",
      " 20000 -   Error: 0.6476    MSE loss: 0.0525\n",
      " 40000 -   Error: 0.2209    MSE loss: 0.0067\n",
      " 60000 -   Error: 0.1623    MSE loss: 0.0037\n",
      " 80000 -   Error: 0.1343    MSE loss: 0.0026\n",
      "100000 -   Error: 0.1170    MSE loss: 0.0020\n",
      "\n",
      "---------- ENDING TRAINING ----------\n",
      "\n",
      "WEIGHTS\n",
      "        W11       W12       W13       W14       W15       W16       W21       W22       W23\n",
      "0 -3.472627  5.843277  5.585736 -3.472627 -3.472627 -3.472627 -9.885644 -9.885644 -9.885644\n",
      "1 -3.472627  5.843277  5.585736 -3.472627 -3.472627 -3.472627 -9.885644 -9.885644 -9.885644\n",
      "\n",
      "\n",
      "\n",
      "---------- STARTING TRAINING FOR 200000 ----------\n",
      "\n",
      " 20000 -   Error: 0.6476    MSE loss: 0.0525\n",
      " 40000 -   Error: 0.2209    MSE loss: 0.0067\n",
      " 60000 -   Error: 0.1623    MSE loss: 0.0037\n",
      " 80000 -   Error: 0.1343    MSE loss: 0.0026\n",
      "100000 -   Error: 0.1170    MSE loss: 0.0020\n",
      "120000 -   Error: 0.1050    MSE loss: 0.0016\n",
      "140000 -   Error: 0.0960    MSE loss: 0.0014\n",
      "160000 -   Error: 0.0890    MSE loss: 0.0012\n",
      "180000 -   Error: 0.0833    MSE loss: 0.0010\n",
      "200000 -   Error: 0.0786    MSE loss: 0.0009\n",
      "\n",
      "---------- ENDING TRAINING ----------\n",
      "\n",
      "WEIGHTS\n",
      "        W11      W12       W13       W14       W15       W16      W21      W22      W23\n",
      "0 -3.795254  6.15271  5.721519 -3.795254 -3.795254 -3.795254 -11.0037 -11.0037 -11.0037\n",
      "1 -3.795254  6.15271  5.721519 -3.795254 -3.795254 -3.795254 -11.0037 -11.0037 -11.0037\n",
      "\n",
      "\n",
      "\n",
      "---------- STARTING TRAINING FOR 500000 ----------\n",
      "\n",
      " 20000 -   Error: 0.6476    MSE loss: 0.0525\n",
      " 40000 -   Error: 0.2209    MSE loss: 0.0067\n",
      " 60000 -   Error: 0.1623    MSE loss: 0.0037\n",
      " 80000 -   Error: 0.1343    MSE loss: 0.0026\n",
      "100000 -   Error: 0.1170    MSE loss: 0.0020\n",
      "120000 -   Error: 0.1050    MSE loss: 0.0016\n",
      "140000 -   Error: 0.0960    MSE loss: 0.0014\n",
      "160000 -   Error: 0.0890    MSE loss: 0.0012\n",
      "180000 -   Error: 0.0833    MSE loss: 0.0010\n",
      "200000 -   Error: 0.0786    MSE loss: 0.0009\n",
      "220000 -   Error: 0.0746    MSE loss: 0.0008\n",
      "240000 -   Error: 0.0711    MSE loss: 0.0008\n",
      "260000 -   Error: 0.0681    MSE loss: 0.0007\n",
      "280000 -   Error: 0.0654    MSE loss: 0.0006\n",
      "300000 -   Error: 0.0630    MSE loss: 0.0006\n",
      "320000 -   Error: 0.0608    MSE loss: 0.0006\n",
      "340000 -   Error: 0.0589    MSE loss: 0.0005\n",
      "360000 -   Error: 0.0571    MSE loss: 0.0005\n",
      "380000 -   Error: 0.0555    MSE loss: 0.0005\n",
      "400000 -   Error: 0.0540    MSE loss: 0.0004\n",
      "420000 -   Error: 0.0526    MSE loss: 0.0004\n",
      "440000 -   Error: 0.0513    MSE loss: 0.0004\n",
      "460000 -   Error: 0.0502    MSE loss: 0.0004\n",
      "480000 -   Error: 0.0490    MSE loss: 0.0004\n",
      "500000 -   Error: 0.0480    MSE loss: 0.0004\n",
      "\n",
      "---------- ENDING TRAINING ----------\n",
      "\n",
      "WEIGHTS\n",
      "        W11       W12       W13       W14       W15       W16        W21        W22        W23\n",
      "0 -4.132396  6.461664  5.884712 -4.132396 -4.132396 -4.132396 -12.414959 -12.414959 -12.414959\n",
      "1 -4.132396  6.461664  5.884712 -4.132396 -4.132396 -4.132396 -12.414959 -12.414959 -12.414959\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_epochs = [100000, 200000, 500000]\n",
    "all_initial_times = []\n",
    "all_final_times = []\n",
    "\n",
    "# learning rate\n",
    "lr = 0.05\n",
    "\n",
    "# set the Input datasets\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "# set the expected output\n",
    "Y_target, output_gate = define_output()\n",
    "\n",
    "# plotting expected output\n",
    "colormap = np.array(['b', 'r'])\n",
    "plt.scatter([i[0] for i in X], [i[1] for i in X], c=colormap[Y_target.flatten()], s=200)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.suptitle(output_gate.upper(), y=1, fontsize=18)\n",
    "plt.title('Color for output {0: blue, 1: red}', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLearning rate:\", lr)\n",
    "\n",
    "for epochs in all_epochs:\n",
    "    # initial time\n",
    "    initial_time = datetime.datetime.now()\n",
    "    all_initial_times.append(initial_time)\n",
    "\n",
    "    # assigning random weights\n",
    "    # 6 for hidden layer, 3 for output layer\n",
    "    initial_W1 = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n",
    "    initial_W2 = np.array([[0.7], [0.8], [0.9]])\n",
    "\n",
    "    W1, W2 = train_network([initial_W1, initial_W2], epochs)\n",
    "\n",
    "    weights_frame = pd.DataFrame({\n",
    "        'W11': [initial_W1[0][0], W1[0][0]],\n",
    "        'W12': [initial_W1[0][1], W1[0][1]],\n",
    "        'W13': [initial_W1[0][2], W1[0][2]],\n",
    "        'W14': [initial_W1[0][0], W1[0][0]],\n",
    "        'W15': [initial_W1[0][0], W1[0][0]],\n",
    "        'W16': [initial_W1[0][0], W1[0][0]],\n",
    "        'W21': [initial_W2[0][0], W2[0][0]],\n",
    "        'W22': [initial_W2[0][0], W2[0][0]],\n",
    "        'W23': [initial_W2[0][0], W2[0][0]],\n",
    "    })\n",
    "\n",
    "    print('\\nWEIGHTS')\n",
    "    print(weights_frame.to_string())\n",
    "    print('\\n')\n",
    "\n",
    "    # final time\n",
    "    final_time = datetime.datetime.now()\n",
    "    all_final_times.append(final_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9YX2ylgR8zx",
    "outputId": "1d08f60b-e260-4515-9dd9-840282df44d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGIC GATE: XOR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Input2</th>\n",
       "      <th>Z</th>\n",
       "      <th>H</th>\n",
       "      <th>U</th>\n",
       "      <th>Y</th>\n",
       "      <th>Target</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>[-3.895159887302203]</td>\n",
       "      <td>[0.019934648870626886]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.444466070230745, -4.138704558059745, 5.899873000256077]</td>\n",
       "      <td>[0.9984132289306397, 0.01569328621728696, 0.9972676932046957]</td>\n",
       "      <td>[4.4006729229138095]</td>\n",
       "      <td>[0.9878796248849324]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.132395941018188, 6.461663751248734, 5.884712384439663]</td>\n",
       "      <td>[0.015791033793323882, 0.9984402422008609, 0.9972260699368929]</td>\n",
       "      <td>[4.400694482818649]</td>\n",
       "      <td>[0.9878798830291259]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.3120701292125574, 2.3229591931889892, 11.78458538469574]</td>\n",
       "      <td>[0.9098717606345105, 0.9107607434278349, 0.9999923789241137]</td>\n",
       "      <td>[-5.56381654701233]</td>\n",
       "      <td>[0.003819471063960799]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input1  Input2  \\\n",
       "0       0       0   \n",
       "1       0       1   \n",
       "2       1       0   \n",
       "3       1       1   \n",
       "\n",
       "                                                             Z  \\\n",
       "0                                              [0.0, 0.0, 0.0]   \n",
       "1   [6.444466070230745, -4.138704558059745, 5.899873000256077]   \n",
       "2   [-4.132395941018188, 6.461663751248734, 5.884712384439663]   \n",
       "3  [2.3120701292125574, 2.3229591931889892, 11.78458538469574]   \n",
       "\n",
       "                                                                H  \\\n",
       "0                                                 [0.5, 0.5, 0.5]   \n",
       "1   [0.9984132289306397, 0.01569328621728696, 0.9972676932046957]   \n",
       "2  [0.015791033793323882, 0.9984402422008609, 0.9972260699368929]   \n",
       "3    [0.9098717606345105, 0.9107607434278349, 0.9999923789241137]   \n",
       "\n",
       "                      U                       Y  Target  Prediction  \n",
       "0  [-3.895159887302203]  [0.019934648870626886]       0           0  \n",
       "1  [4.4006729229138095]    [0.9878796248849324]       1           1  \n",
       "2   [4.400694482818649]    [0.9878798830291259]       1           1  \n",
       "3   [-5.56381654701233]  [0.003819471063960799]       0           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_vals = []\n",
    "h_vals = []\n",
    "u_vals = []\n",
    "y_vals = []\n",
    "preds = []\n",
    "\n",
    "for point in X:\n",
    "    point = np.array(point)\n",
    "    z = np.dot(point, W1)\n",
    "    z_vals.append(z)\n",
    "\n",
    "    h = sigmoid(z)\n",
    "    h_vals.append(h)\n",
    "\n",
    "    op = np.dot(h, W2)\n",
    "    u_vals.append(op)\n",
    "\n",
    "    y_cap = sigmoid(op)\n",
    "    y_vals.append(y_cap)\n",
    "\n",
    "    preds.append(round(y_cap[0]))\n",
    "\n",
    "print(f\"LOGIC GATE: {output_gate.upper()}\")\n",
    "pd.DataFrame.from_dict({\n",
    "    'Input1': X.reshape(-1)[::2],\n",
    "    'Input2': X.reshape(-1)[1::2],\n",
    "    'Z': z_vals,\n",
    "    'H': h_vals,\n",
    "    'U': u_vals,\n",
    "    'Y': y_vals,\n",
    "    'Target': Y_target.reshape(-1),\n",
    "    'Prediction': preds\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Complexity\n",
    "Time complexity is the amount of time taken by an algorithm to run, as a function of the length of the input. It measures the time taken to execute each statement of code in an algorithm.\n",
    "\n",
    "Our Neural Network consists of 2 input nodes going into a hidden layer with 3 nodes which in turn goes to the output layer with 1 node. The weighted sum of each layer is going through a sigmoid activation function.\n",
    "\n",
    "<img src=\"NN.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(time):\n",
    "    return datetime.timedelta(\n",
    "        hours=time.hour, minutes=time.minute, seconds=time.second, microseconds=time.microsecond\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for  100000 epochs:     0:00:03.706519\n",
      "Total time taken for  200000 epochs:     0:00:07.351648\n",
      "Total time taken for  500000 epochs:     0:00:18.610235\n"
     ]
    }
   ],
   "source": [
    "for initial_time, final_time, epochs in zip(all_initial_times, all_final_times, all_epochs):\n",
    "    initial_timedelta = convert_time(initial_time)\n",
    "    final_timedelta = convert_time(final_time)\n",
    "\n",
    "    # total time taken by program\n",
    "    print('Total time taken for %7d epochs: %18s' %(epochs, final_timedelta-initial_timedelta))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN_OR_Gate_via_Backprop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
